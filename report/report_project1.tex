\documentclass[10pt,conference,compsocconf]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}	% For figure environment
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}

\newcommand{\beginsupplement}{%
	\setcounter{table}{0}
	\renewcommand{\thetable}{S\arabic{table}}%
	\setcounter{figure}{0}
	\renewcommand{\thefigure}{S\arabic{figure}}%
}

\begin{document}
\title{CS-433 Machine Learning Project 1}

\author{
  Matthias Minder, Zora Oswald, Silvan Stettler\\
  
}

\maketitle

\begin{abstract}
Collision events in the Large Hadron Collider at CERN do not create directly observable results. An essential part of elementary particles such as the Higgs boson therefore rely on classifying the collisions based on a number of variables that can be measured in the collider. For that purpose, a logistic regression and a support vector machine classifier were trained and cross-validated. Using the support vector machine classifier, the presence of a Higgs boson could be accurately predicted in 82.243\% of the cases.  
\end{abstract}

\section*{Introduction} 
In our dataset, a vector containing 30 dimensions describes one collision event. A binary classification algorithm can be used to predict the presence of a Higgs boson based on this feature vector. The model is trained with data from collisions for which the existence of a Higgs boson is determined. The training data-set contains 250000 collisions.
Our classifications of the collision events consist of three main steps:
\begin{enumerate}
\item Normalization and imputation of missing data 
\item Parameter optimization using cross-validation
\item Predictions on test data made up of 568'238 collisions using the best-fitting binary model 
\end{enumerate}
Furthermore, the importance of variables for the final model was assessed using best subset selection.
\section*{Methods}
As a first step, all features were transformed to have mean zero and unit variance, disregarding missing values.
\par 
As a second step, missing values were imputed. These missing values are due to physical measures being made impossible under certain conditions. However, since the classification methods used in the scope of this project don't naturally support the presence of missing values, they were imputed using the following linear regression approach: 
\par
Analysis of the raw data showed that there are a total of six distinct patterns of missing features. A pattern of observation $\boldsymbol{x}$, denoted $P(\boldsymbol{x})$, is characterized by values of $\boldsymbol{x}$ missing in dimensions $M$ and values being present in dimensions $M'$. Approximately 60'000 observations of the training data contained no missing values, i.e. $M_{P(\boldsymbol{x})} = \emptyset$. For each incomplete pattern $P_i(\boldsymbol{x})$ and every missing feature $l \in M_{P_i(\boldsymbol{x})}$, a linear regression was fitted with gradient descent to complete observations, taking all features $k \in M'_{P_i(\boldsymbol{x})}$ as observations and feature $l$ as response. This fit was then applied to impute the missing feature $l$ of all $\boldsymbol{x}$ corresponding to $P_i(\boldsymbol{x})$. Missing values of the test data were imputed using the fits on the training data.  
\par
This method for missing value imputation follows the natural structure of the data: Observations corresponding to the same physical preconditions leading to a specific pattern of missing values were all subjected to the same fit for missing value imputation. Simple linear regression was chosen due to its easy interpretability. Fitting more complex regression models would only make limited sense, since the absence of "true" values for a given missing value pattern makes reasonable model comparison impossible. Finally, we chose this approach over "simple", constant imputation using the feature mean or median because it allows to capture more of the data variability. 
\par
However, by imputing missing values, the information about their underlying physical reasons is lost. To capture this information, dummy variables were created that encode every non-complete pattern of missing values. 
%\begin{align*}
%{x}_{ij, j \in M} &\approx w_0 + \sum_{k \in M'} w_k {x}_{ik}\\
%\boldsymbol{w}^* = \underset{x}{argmin}\sum_i & ({x}_{ij, j \in M} - \boldsymbol{x}^T_{ik, k \in M'} \boldsymbol{w})^2\\
%{x}_{na,ij, j \in M} &= w_0 + \sum_{k \in M'} w_k {x}_{na,ik}
%\end{align*} 
\par
Thereafter, two general model categories were fitted to the preprocessed data: $L_2$ regularized logistic regression and support vector machines. Gradient descent was used to minimize the cost function for $L_2$ regularized logistic regression that was shown in class.
\par
In addition to logistic regression, the collisions were classified with a Support Vector Machine (SVM) method. The basic idea behind SVM methods is to find a hyperplane that separates the data-set into two classes. This can be achieved by minimizing a cost function based on hinge loss \cite{SVM_ref}.
\begin{equation}
\mathcal{L}(\boldsymbol{w}) = C \sum_{n=1}^N max(0,1-y_n \boldsymbol{x}_n^T\boldsymbol{w}) + \frac{1}{2}||\boldsymbol{w}||^2 \hspace{5mm} y_i \in \{-1,1\}
\end{equation}  
If the output is predicted on the right side of the hyperplane, meaning that $sgn(y_i) = sgn(\boldsymbol{x}_n^T\boldsymbol{w})$, then that particular observation does not contribute to the loss. Points on the wrong side of the hyperplane or too close to the hyperplane contribute, however. Therefore, the gradient of the hinge loss $\nabla \mathcal{L}$ either takes the value $\boldsymbol{0}$ or $-y_n\boldsymbol{x_n}$ plus the contribution of the penalty function $\lambda \boldsymbol{w}$. This expression for the gradient was used in order to minimize the SVM cost function by stochastic gradient descent.
\par
The feature vector $\boldsymbol{X}$ that was used as input for both models contains a constant and polynomial basis expansion (degree 2) terms so that
\begin{equation}
\boldsymbol{x}_{enh.} = [1 \hspace{2mm} \boldsymbol{x}_n \hspace{2mm} x_{ni} x_{nj}] \hspace{5mm} i \in dim(\boldsymbol{x}_n), j < i
\end{equation}
Both $L_2$-regularized logistic regression and SVM depend on a hyperparameter which controls the penalization of false classification. This parameter was chosen to maximize accuracy, as determined in ten-fold cross-validation. The different classification methods were compared in terms of their achieved accuracy on an independent test set. 
\par
In order to gain insight into the decision making process of our classifier, a forward-greedy best subset selection (BSS) was performed. The training set was randomly split into a training and a validation set containing $80\%$ and $20\%$ of the original training data respectively. Then, starting with an empty model (containing no features), the following procedure was repeated: 
\begin{enumerate}
	\item For every feature not yet in the model, the model plus that respective feature was fitted to the training set.
	\item The accuracy of every fit was assessed on the validation set.  
	\item The feature, including which the greatest accuracy was obtained, was included into the model.
\end{enumerate}
These three steps were repeated until the full model was obtained. This allows to obtain an importance ordering for the variables. The process was repeated ten times to assess result stability. Furthermore, the dummy variables were disregarded during this process in order to obtain an importance ordering of the original data. Finally, for performance reasons, the gradient descent method was run with less iterations and a larger step size.
\section*{Results}
The following graphs show the accuracies obtained during cross-validation. The best results were obtained with enhanced data and $\lambda$ smaller than 10\textsuperscript{-3}. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.3\textwidth]{accuracy_log_and_SVM.png}
	\caption{Reg. logistic regression and SVM 10-fold cross-validation. Gradient descent with 100000 iterations, $\gamma$ = 0.001}
\end{figure}
The fact that train and test accuracies are very similar and equally good for small $\lambda$ indicate that overfitting does not occur. It is rather probable that the model underfits and more training iterations could still improve the results. Moreover, there is no significant difference between the performance of logistic regression or support vector machines. This could be explained by the fact that both classifiers use linear boundaries which might not be adapted to our data-set. Both models produce a proportion of misclassified collisions that would usually be deemed to be unacceptably high \cite{advice}, which further hints that both models are not the best choice with our dataset.
\par
% interpretation vo BSS
\begin{figure}[H]
	\centering
	\includegraphics[width=0.3\textwidth]{accuracy_plot.pdf}
	\caption{Mean accuracy for a given number of features in BSS with SVM, over 10 repetitions. $\lambda = 5 \cdot 10^{-8}$, $\gamma = 0.01$, 5000 iterations for gradient descent.}
\end{figure}
Figure 2 shows the accuracy depending on the amount of features included in the BSS. 15 features suffice for the model, while adding additional features to the model leads a lower accuracy likely due to overfitting. This suggests that the omitted variables are noisy and thus only deteriorate classifier accuracy.
%%% Verbessere 
However, for computational reasons this plot was obtained using a gradient descent with decreased precision. A model fitted consisting only the 15 most important features as determined by BSS was fitted with a more refined gradient descent method (data not shown). However, this model performed worse on the test set than the full model, suggesting that the overfitting phenomenon decreases as the SVM fit grows more precise.
Moreover, BSS showed that certain features are consistently included earlier into the model than others, suggesting that they are much more important for the classifier than others (see Supplementary Figure 1). 
\section*{Conclusion}
We presented classifiers based on logistic regression and support vector machines and using polynomial basis expansions. In terms of accuracy, the performance of both classifiers is similar and relatively poor. However, only classifiers based on SVMs and logistic regression with linear decision boundaries in the augmented feature space were assessed. A better performance may be achieved using other, more sophisticated classification models such as kernel SVMs, random forest or neural networks. Moreover, we assessed variable importance for the SVM model, allowing to gain physical insight from our fit.   

%%% Bibliography
\bibliographystyle{IEEEtran}
\bibliography{literature-project1}

\beginsupplement
\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{fwd_heat.pdf}
	\caption{Features present at every iteration of BSS, averaged over 10 iterations. A value of 1 means that the specific feature was part of the model corresponding to a given number of features in all of the models, while a value of 0 means that it was absent. }
\end{figure}

\end{document}
